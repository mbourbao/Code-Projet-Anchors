{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertModel, DistilBertConfig\n",
    "import ipywidgets\n",
    "\n",
    "import IProgress\n",
    "from transformers import DistilBertTokenizer, DistilBertForMaskedLM\n",
    "import torch\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import os\n",
    "import string \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "os.chdir(\"C:/Users/33651/Documents/Projet_Anchors/CODE/\")\n",
    "from classifier import *\n",
    "from dict_local import * \n",
    "from perturbation import * \n",
    "from couverture import * \n",
    "from select_cov import * \n",
    "import itertools\n",
    "\n",
    "from string import *\n",
    "from Perturb_Bert_Plusieurs_mots import *\n",
    "\n",
    "import copy\n",
    "import itertools\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meilleur_ancre_general import * \n",
    "from Perturb_Bert_One_mots import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook associé à l'article "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "## CHARGEMENT DES DONNEES ##\n",
    "############################\n",
    "\n",
    "filepath_dict = {'yelp':   'C:/Users/33651/Documents/Projet_Anchors/sentiment labelled sentences/sentiment labelled sentences/yelp_labelled.txt',\n",
    "                 'amazon': 'C:/Users/33651/Documents/Projet_Anchors/sentiment labelled sentences/sentiment labelled sentences/amazon_cells_labelled.txt',\n",
    "                 'imdb':   'C:/Users/33651/Documents/Projet_Anchors/sentiment labelled sentences/sentiment labelled sentences/imdb_labelled.txt'}\n",
    "\n",
    "df_list = []\n",
    "for source, filepath in filepath_dict.items():\n",
    "    df = pd.read_csv(filepath, names=['sentence', 'label'], sep='\\t')\n",
    "    df['source'] = source  # Add another column filled with the source name\n",
    "    df_list.append(df)\n",
    "df_list\n",
    "\n",
    "\n",
    "df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement de la boîte noire $f$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val accuracy 0.8\n"
     ]
    }
   ],
   "source": [
    "df.set_axis(['sentence', 'label',\"source\"],  axis='columns', inplace=True)\n",
    "sentences = df['sentence'].values \n",
    "#Récupérer les labels\n",
    "y = df['label'].values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train, test, train_labels, test_labels = sklearn.model_selection.train_test_split(sentences, y, test_size=.2, random_state=42)\n",
    "train, val, train_labels, val_labels = sklearn.model_selection.train_test_split(train, train_labels, test_size=.1, random_state=42)\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)\n",
    "val_labels = np.array(val_labels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=1)\n",
    "vectorizer.fit(train)\n",
    "train_vectors = vectorizer.transform(train)\n",
    "test_vectors = vectorizer.transform(test)\n",
    "val_vectors = vectorizer.transform(val)\n",
    "\n",
    "\n",
    "c = sklearn.linear_model.LogisticRegression()\n",
    "# c = sklearn.ensemble.RandomForestClassifier(n_estimators=500, n_jobs=10)\n",
    "c.fit(train_vectors, train_labels)\n",
    "preds = c.predict(val_vectors)\n",
    "print('Val accuracy', sklearn.metrics.accuracy_score(val_labels, preds))\n",
    "def predict_lr(texts):\n",
    "    return c.predict(vectorizer.transform(texts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple 1 - Visualisation d'une ancre "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: positive\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "explainer = anchor_text.AnchorText(nlp, ['negative', 'positive'], use_unk_distribution=True)\n",
    "\n",
    "text = \"The reception has been generally good\"\n",
    "pred = explainer.class_names[predict_lr([text])[0]]\n",
    "print('Prediction: %s' % pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "label = predict_lr([text])[0]\n",
    "\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nouvelle implémentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "les_candidats ['the', 'reception', 'has', 'been', 'generally', 'good']\n",
      "Anchor: ['good'] Precision: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['good']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tau = 0.15\n",
    "\n",
    "meilleur_ancre_bis_new(df,text,500,\"UNK\",label,tau,vectorizer, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec le package Anchors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: good\n",
      "Precision: 1.00\n"
     ]
    }
   ],
   "source": [
    "exp = explainer.explain_instance(text, predict_lr, threshold=0.95)\n",
    "print('Anchor: %s' % (' AND '.join(exp.names())))\n",
    "print('Precision: %.2f' % exp.precision())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorisation des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " liste = [\"I like this phone !\", \"It is good place, i like !\", \"  Good ! ! I really love this movie.\",\"  I had a good time, I like this place\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I like this phone !', 'It is good place, i like !', '  Good ! ! I really love this movie.', '  I had a good time, I like this place']\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(liste)\n",
    "print(len(liste))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifiant des mots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'like': 4,\n",
       " 'this': 10,\n",
       " 'phone': 7,\n",
       " 'it': 3,\n",
       " 'is': 2,\n",
       " 'good': 0,\n",
       " 'place': 8,\n",
       " 'really': 9,\n",
       " 'love': 5,\n",
       " 'movie': 6,\n",
       " 'had': 1,\n",
       " 'time': 11}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "tf = vectorizer.fit_transform(liste)\n",
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
       "       [1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0],\n",
       "       [1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple de perturbation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Préparation de la phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'reception', 'has', 'been', 'generally', 'good']\n"
     ]
    }
   ],
   "source": [
    "phrase_decoup = word_tokenize(text.lower())\n",
    "print(phrase_decoup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Affichage des perturbations (Nouvelle implémentation - Perturbation déterministe )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UNK reception UNK UNK generally good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the UNK has UNK generally good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNK UNK UNK been generally good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the reception UNK UNK UNK good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the UNK has been UNK good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UNK reception UNK been UNK good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the UNK UNK UNK UNK good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UNK UNK has been UNK good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the UNK has UNK UNK good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the UNK has UNK UNK good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>the UNK has been UNK good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       0\n",
       "0   UNK reception UNK UNK generally good\n",
       "1         the UNK has UNK generally good\n",
       "2        UNK UNK UNK been generally good\n",
       "3         the reception UNK UNK UNK good\n",
       "4              the UNK has been UNK good\n",
       "5        UNK reception UNK been UNK good\n",
       "6               the UNK UNK UNK UNK good\n",
       "7              UNK UNK has been UNK good\n",
       "8               the UNK has UNK UNK good\n",
       "9               the UNK has UNK UNK good\n",
       "10             the UNK has been UNK good"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_perturb_bis4(phrase_decoup,[\"good\"],10,\"UNK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Affichage des perturbations (Package Anchors - Perturbation déterministe )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['UNK reception has been UNK good'],\n",
       "       ['UNK reception UNK been generally good'],\n",
       "       ['The reception UNK been UNK good'],\n",
       "       ['The UNK has been generally good'],\n",
       "       ['UNK UNK has been UNK good'],\n",
       "       ['UNK UNK UNK UNK UNK good'],\n",
       "       ['The UNK has UNK generally good'],\n",
       "       ['UNK UNK UNK UNK UNK good'],\n",
       "       ['UNK reception UNK been UNK good'],\n",
       "       ['The reception UNK been UNK good']], dtype='<U80')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un seul mot caché"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the reception has [MASK] generally good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the reception has been [MASK] good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the reception has been [MASK] good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[MASK] reception has been generally good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the [MASK] has been generally good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the [MASK] has been generally good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the reception has [MASK] generally good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the reception has been [MASK] good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[MASK] reception has been generally good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the reception has [MASK] generally good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>the reception has [MASK] generally good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           0\n",
       "0    the reception has [MASK] generally good\n",
       "1         the reception has been [MASK] good\n",
       "2         the reception has been [MASK] good\n",
       "3   [MASK] reception has been generally good\n",
       "4         the [MASK] has been generally good\n",
       "5         the [MASK] has been generally good\n",
       "6    the reception has [MASK] generally good\n",
       "7         the reception has been [MASK] good\n",
       "8   [MASK] reception has been generally good\n",
       "9    the reception has [MASK] generally good\n",
       "10   the reception has [MASK] generally good"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_perturb_bert_one('The reception has been generally good',[\"good\"],10,\"[MASK]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plusieurs mots cachés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The [MASK] has [MASK] [MASK] good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The reception [MASK] [MASK] generally good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[MASK] [MASK] [MASK] [MASK] generally good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[MASK] reception [MASK] been generally good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[MASK] reception has [MASK] generally good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The [MASK] [MASK] [MASK] [MASK] good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[MASK] reception [MASK] [MASK] [MASK] good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[MASK] reception has been generally good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[MASK] reception has been generally good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[MASK] reception [MASK] [MASK] [MASK] good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[MASK] [MASK] [MASK] been generally good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              0\n",
       "0             The [MASK] has [MASK] [MASK] good\n",
       "1    The reception [MASK] [MASK] generally good\n",
       "2    [MASK] [MASK] [MASK] [MASK] generally good\n",
       "3   [MASK] reception [MASK] been generally good\n",
       "4    [MASK] reception has [MASK] generally good\n",
       "5          The [MASK] [MASK] [MASK] [MASK] good\n",
       "6    [MASK] reception [MASK] [MASK] [MASK] good\n",
       "7      [MASK] reception has been generally good\n",
       "8      [MASK] reception has been generally good\n",
       "9    [MASK] reception [MASK] [MASK] [MASK] good\n",
       "10     [MASK] [MASK] [MASK] been generally good"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_perturb_bert('The reception has been generally good',[\"good\"],10,\"[MASK]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple de perturbation générative - Anchors Morgane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Un seul mot perturbé "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple perturbation 1 (un seul mot caché) : the award has been generally good\n",
      "Exemple perturbation 2 (un seul mot caché) : the reception has been ##ably good\n",
      "Exemple perturbation 3 (un seul mot caché) : the reception delivers been generally good\n",
      "Exemple perturbation 4 (un seul mot caché) : the reception has been garnered good\n"
     ]
    }
   ],
   "source": [
    "print(\"Exemple perturbation 1 (un seul mot caché) :\",gener_perturb_bert_one(\"the [MASK] has been generally good\",'The reception has been generally good',torch))\n",
    "print(\"Exemple perturbation 2 (un seul mot caché) :\", gener_perturb_bert_one(\"the reception has been [MASK] good\",'The reception has been generally good',torch))\n",
    "print(\"Exemple perturbation 3 (un seul mot caché) :\",gener_perturb_bert_one(\"the reception [MASK] been generally good\",'The reception has been generally good',torch))\n",
    "print(\"Exemple perturbation 4 (un seul mot caché) :\",gener_perturb_bert_one(\"the reception has been [MASK] good\",'The reception has been generally good',torch))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " On peut remarquer que les perturbations générées sont plus cohérentes qu'avec la méthode déterministe  $ \\texttt{UNK }$;  Appliquons la même méthode en perturbant plusieurs instances : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple perturbation 1 (Plusieurs mots cachés) : reaction reception has been sung good\n",
      "Exemple perturbation 2 (Plusieurs mots cachés) : The traditional milk occur generally good\n",
      "Exemple perturbation 3 (Plusieurs mots cachés) : The reception may been ) good\n",
      "Exemple perturbation 4 (Plusieurs mots cachés) : preview reception here user description good\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Exemple perturbation 1 (Plusieurs mots cachés) :\", gener_perturb_bert(\"[MASK] reception has been [MASK] good\",'The reception has been generally good',torch,device))\n",
    "\n",
    "print(\"Exemple perturbation 2 (Plusieurs mots cachés) :\",gener_perturb_bert(\"The [MASK] [MASK] [MASK] generally good\",'The reception has been generally good',torch,device))\n",
    "print(\"Exemple perturbation 3 (Plusieurs mots cachés) :\",gener_perturb_bert(\"The reception [MASK] been [MASK] good\",'The reception has been generally good',torch,device))\n",
    "print(\"Exemple perturbation 4 (Plusieurs mots cachés) :\",gener_perturb_bert(\"[MASK] reception [MASK] [MASK] [MASK] good\",'The reception has been generally good',torch,device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut constaster que les perturbations ont moins de sens que si on perturbe un unique mot, l'algorithme a plus de mal de deviner le sens de la phrase de départ car il y a trop de mot cacher. Mais semble toujours plus réaliste que la perturbation déterministe. Elle reste tout de même plus longue que la méthode déterministe mais beaucoup plus rapide que si on perturbe un seul mot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour éviter les confrontations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertModel, DistilBertConfig\n",
    "import ipywidgets\n",
    "\n",
    "import IProgress\n",
    "from transformers import DistilBertTokenizer, DistilBertForMaskedLM\n",
    "import torch\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import os\n",
    "import string \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "os.chdir(\"C:/Users/33651/Documents/Projet_Anchors/CODE/\")\n",
    "from classifier import *\n",
    "from dict_local import * \n",
    "from perturbation import * \n",
    "from couverture import * \n",
    "from select_cov import * \n",
    "import itertools\n",
    "\n",
    "from string import *\n",
    "from Perturb_Bert_Plusieurs_mots import *\n",
    "\n",
    "import copy\n",
    "import itertools\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meilleur_ancre_general import * \n",
    "from Perturb_Bert_One_mots import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val accuracy 0.8\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "## CHARGEMENT DES DONNEES ##\n",
    "############################\n",
    "\n",
    "filepath_dict = {'yelp':   'C:/Users/33651/Documents/Projet_Anchors/sentiment labelled sentences/sentiment labelled sentences/yelp_labelled.txt',\n",
    "                 'amazon': 'C:/Users/33651/Documents/Projet_Anchors/sentiment labelled sentences/sentiment labelled sentences/amazon_cells_labelled.txt',\n",
    "                 'imdb':   'C:/Users/33651/Documents/Projet_Anchors/sentiment labelled sentences/sentiment labelled sentences/imdb_labelled.txt'}\n",
    "\n",
    "df_list = []\n",
    "for source, filepath in filepath_dict.items():\n",
    "    df = pd.read_csv(filepath, names=['sentence', 'label'], sep='\\t')\n",
    "    df['source'] = source  # Add another column filled with the source name\n",
    "    df_list.append(df)\n",
    "df_list\n",
    "\n",
    "\n",
    "df = pd.concat(df_list)\n",
    "df.set_axis(['sentence', 'label',\"source\"],  axis='columns', inplace=True)\n",
    "sentences = df['sentence'].values \n",
    "#Récupérer les labels\n",
    "y = df['label'].values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train, test, train_labels, test_labels = sklearn.model_selection.train_test_split(sentences, y, test_size=.2, random_state=42)\n",
    "train, val, train_labels, val_labels = sklearn.model_selection.train_test_split(train, train_labels, test_size=.1, random_state=42)\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)\n",
    "val_labels = np.array(val_labels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=1)\n",
    "vectorizer.fit(train)\n",
    "train_vectors = vectorizer.transform(train)\n",
    "test_vectors = vectorizer.transform(test)\n",
    "val_vectors = vectorizer.transform(val)\n",
    "\n",
    "\n",
    "c = sklearn.linear_model.LogisticRegression()\n",
    "# c = sklearn.ensemble.RandomForestClassifier(n_estimators=500, n_jobs=10)\n",
    "c.fit(train_vectors, train_labels)\n",
    "preds = c.predict(val_vectors)\n",
    "print('Val accuracy', sklearn.metrics.accuracy_score(val_labels, preds))\n",
    "def predict_lr(texts):\n",
    "    return c.predict(vectorizer.transform(texts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec le package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "explainer2 = anchor_text.AnchorText(nlp, ['negative', 'positive'], use_unk_distribution=False ) #BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = \"The reception has been generally good\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer2.explain_instance(text, predict_lr, threshold=0.95, verbose=False, onepass=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['recent growth has proven generally good'],\n",
       "       ['blood , has proven relatively good'],\n",
       "       ['den ##ty has another very good'],\n",
       "       ['Critical reception scores do ##ishly good'],\n",
       "       ['п ##ل ##ে - as good'],\n",
       "       ['ever function has made seven good'],\n",
       "       ['Any activity has got to good'],\n",
       "       ['critical reception has been generally good'],\n",
       "       ['film reception has been very good'],\n",
       "       ['home have now been great good']], dtype='<U80')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "les_candidats ['computer', 'good', 'is', 'this']\n",
      "1\n",
      "les phrases perturbées ['This is crystal computer', 'This is whose computer', 'This is elementary computer', 'This is good computer', 'This is good computer', 'bandwidth is good computer', 'This class robotic computer', 'This man ##ized computer', 'This ##h good computer', 'This is going computer', 'file is ##sa computer', 'This enhanced efficient computer', 'This table program computer', 'most # good computer', 'This is good computer', 'This is good computer', 'Air is good computer', 'This ##th flow computer', 'This is good computer', 'ok 8 good computer', 'bug is good computer', 'text is ##on computer', 'go without good computer', 'This modern intelligent computer', 'This is good computer', 'training is good computer', 'This into good computer', '! | good computer', 'This ##ally card computer', 'flash is ##aa computer', 'This is color computer', 'This is efficient computer', 'This is good computer', 'bold still good computer', 'This ##acle desk computer', 'photos ##ized ##how computer', 'This is good computer', 'computing is simple computer', 'This mac ##text computer', 'this ##n good computer', 'this is good computer', 'This is junk computer', 'operation security ##frame computer', 'This is complete computer', 'This second good computer', 'This their good computer', 'ours is good computer', 'never pretty good computer', 'This is active computer', 'This now good computer', 'This is good computer']\n",
      "les phrases perturbées ['This article good computer', 'Light is good old', 'This left good computer', 'infrastructure is good computer', 'com not good ##work', 'handy – good computer', 'This our good master', 'This said good computer', 'This seem good order', 'ever most good computer', 'Ya * good yesterday', 'This your good neighborhood', 'talking is good computer', 'This proved good month', 'This is good version', 'signal is good computer', 'All is good confidence', 'This is good rainfall', 'snap By good computer', 'This is good growth', 'This is good scouting', 'This is good looking', 'This model good computer', 'Linux is good computer', 'Coffee is good foundation', 'And ##less good money', 'This is good computer', 'k exceptionally good blood', 'user ##ily good computer', 'This : good ones', 'und yet good causes', 'god ##my good computer', 'This is good meditation', 'everyone ##lessly good the', 'another . good stuff', 'Grass is good management', 'This Is good doctrine', 'oh like good computer', 'oh is good computer', 'This is good computer', 'This is good talk', 'This is good computer', 'when contains good moment', 'This saves good computer', 'Mind is good computer', 'This is good nature', 'practice is good elsewhere', 'This its good living', 'This ##a good book', 'This is good computer', 'learning is good computer']\n",
      "les phrases perturbées ['2 is mandatory services', '9 is unclear ##kawa', 'This is mandatory :', 'father is having computer', 'programmer is cell computer', 'This is source ##um', 'breakfast is good computer', 'surname is at name', 'This is basic us', 'This is good computer', 'This is good computer', 'Name is good computer', 'This is good above', 'equation is lonely cup', 'This is good data', 'info is good computer', 'This is green computer', 'constitution is politically forests', 'auto is good computer', 'radio is learning computer', 'music is good computer', 'This is data ##n', 'wireless is good computer', 'This is good computer', 'research is ##me computer', 'This is good though', 'Type is uncertain ##ft', 'This is good speech', 'This is THE computer', 'This is numbered because', 'This is Google computer', 'joy is good choice', 'voter is to ##ama', 'architecture is good !', 'This is false ##p', 'Jane is good computer', 'This is generalized percent', 'This is good dance', 'function is 3 metres', 'currency is ##f session', 'This is good computer', 'This is usually ##c', 'This is project computer', 'literacy is always ##more', 'This is good manners', 'This is good computer', 'This is good to', 'probability is ##omo ##f', 'This is good computer', 'This is municipal computer', 'This is good report']\n",
      "les phrases perturbées ['This ##ar ##corn computer', 'This second good cause', 'B is complete computer', 'This is good computer', 'For truly good computer', 'This example school computer', 'key is br when', 'sir is good computer', 'This knows good tomorrow', ', grows good }', 'darkness is good hunting', 'er data ##nic computer', 'dear felt good ##up', 'This mac list |', 'harmony is good sleep', 'This little ##ation reference', 'fi ##an ##π cup', 'oil is good energy', 'This will good friend', 'This ##oppy technical computer', 'This three si characters', 'This is ##le computer', 'This is good computer', 'nice feel good harvest', 'major z ##ness function', 'This ##00 use computer', '1957 ##tic ##op fund', 'k is precious computer', 'This is ##tation computer', 'per internet fast computer', 'spring is good evidence', 'dip in ##nc →', 'This is with computer', 'This is good computer', 'vision is good website', 'This ##4 : computer', 'child is good computer', 'help is good computer', 'This network world computer', 'This is good dream', 'This is good computer', 'This ##pi ##less computer', '1990 found good world', 'This is good argument', 'This features good computer', '? Oh good guy', 'success is difficult divided', 'This ##32 ##5 computer', 'neo ##st ##oid computer', 'This requires good note', 'server ##chan ##tation computer']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "label = predict_lr([text])[0]\n",
    "\n",
    "print(label)\n",
    "explainer = anchor_text.AnchorText(nlp, ['negative', 'positive'], use_unk_distribution=True)\n",
    "np.random.seed(1)\n",
    "\n",
    "phrase = \"This is good computer\"\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform([phrase])\n",
    "ph_expli_tok= vectorizer.get_feature_names()\n",
    "les_candidats = ph_expli_tok\n",
    "print(\"les_candidats\",les_candidats)\n",
    "meilleur_prec = 0 \n",
    "prec_temp = 0\n",
    "best_ancre = []\n",
    "precision_tous_deter = [] \n",
    "precision_tous_bert = []\n",
    "candidat_tous = []\n",
    "cov = []\n",
    "couverture = 1+0.5\n",
    "cov_total = []\n",
    "vrai_cov = []\n",
    "vrai = 0 \n",
    "torch = torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "for i in range(1,len(les_candidats)):\n",
    "    comb_temp = []\n",
    "    couverture = couverture - 0.5\n",
    "    cov.append(couverture)\n",
    "    print(i)    \n",
    "    for c in itertools.combinations(les_candidats,i):\n",
    "        x= list(c)\n",
    "        comb_temp.append(x)\n",
    "       \n",
    "        cov_total.append(couverture)         \n",
    "    for p in range(len(comb_temp)) : \n",
    "           \n",
    "            if p == 0 and len(best_ancre) == 0 : #tout premier\n",
    "                perturb = generation_perturb_bis4(ph_expli_tok,comb_temp[p],50,\"UNK\")\n",
    "                perturb_bert = generation_perturb_bert( \"This is good computer\",comb_temp[p], 50)\n",
    "                exp2 = np.array(perturb)\n",
    "                exp2_bert = np.array(perturb_bert)\n",
    "                \n",
    "                \n",
    "                exp3 = list(exp2)\n",
    "                l =[]\n",
    "                for j in range(len(exp2)):\n",
    "                     l.append(exp3[j][0])\n",
    "                resultat_deter = classif2(df,0.2,l)\n",
    "               # print(resultat)\n",
    "                prec_temp_deter = len(resultat_deter[resultat_deter==label])/len(resultat_deter)\n",
    "                ###############BERT\n",
    "                mes_phr_perturb = []\n",
    "                for pm in range(len(exp2_bert)):\n",
    "                \n",
    "                    phra_pe = gener_perturb_bert(exp2_bert[pm][0],\"This is good computer\",torch)\n",
    "                \n",
    "                    mes_phr_perturb.append(phra_pe)\n",
    "                print(\"les phrases perturbées\",mes_phr_perturb)\n",
    "                resultat_bert = classif2(df,0.2,mes_phr_perturb)\n",
    "               # print(resultat)\n",
    "                prec_temp_bert = len(resultat_bert[resultat_bert==label])/len(resultat_bert)\n",
    "                \n",
    "                meilleur_prec_deter = prec_temp_deter\n",
    "                meilleur_prec_bert = prec_temp_bert\n",
    "                \n",
    "                \n",
    "                \n",
    "                best_ancre_deter = comb_temp[p]\n",
    "                best_ancre_bert = comb_temp[p]\n",
    "                precision_tous_deter.append(meilleur_prec_deter)\n",
    "                precision_tous_bert.append(meilleur_prec_bert)\n",
    "                \n",
    "                vrai = cov_bis(comb_temp[p],sentences)\n",
    "                vrai_cov.append(vrai)\n",
    "                candidat_tous.append(comb_temp[p])\n",
    "                #print(meilleur_prec)\n",
    "            else: \n",
    "             #   print(\"com\", comb_temp[p])\n",
    "                candidat_tous.append(comb_temp[p])\n",
    "                perturb = generation_perturb_bis4(ph_expli_tok,comb_temp[p],50,\"UNK\")\n",
    "                perturb_bert = generation_perturb_bert( \"This is good computer\",comb_temp[p], 50)\n",
    "                exp2 = np.array(perturb)\n",
    "                exp2_bert = np.array(perturb_bert)\n",
    "                \n",
    "                ##################DETERMINISTE \n",
    "                exp3 = list(exp2)\n",
    "                l =[]\n",
    "                for j in range(len(exp2)):\n",
    "                    l.append(exp3[j][0])\n",
    "                resultat_deter = classif2(df,0.2,l)\n",
    "               # print(resultat)\n",
    "                prec_temp_deter = len(resultat_deter[resultat_deter==label])/len(resultat_deter)\n",
    "                \n",
    "                ############################BERT \n",
    "                mes_phr_perturb = []\n",
    "                for pm in range(len(exp2_bert)):\n",
    "                \n",
    "                    phra_pe = gener_perturb_bert(exp2_bert[pm][0],\"This is good computer\",torch)\n",
    "                \n",
    "                    mes_phr_perturb.append(phra_pe)\n",
    "                print(\"les phrases perturbées\",mes_phr_perturb)\n",
    "                resultat_bert = classif2(df,0.2,mes_phr_perturb)\n",
    "               # print(resultat)\n",
    "                prec_temp_bert = len(resultat_bert[resultat_bert==label])/len(resultat_bert)\n",
    "                \n",
    "                #################################################################\n",
    "                \n",
    "                precision_tous_deter.append(prec_temp_deter)\n",
    "                precision_tous_bert.append(prec_temp_bert)\n",
    "                \n",
    "                vrai = cov_bis(comb_temp[p],sentences)\n",
    "                vrai_cov.append(vrai)\n",
    "               \n",
    "                \n",
    "                if prec_temp_deter == meilleur_prec_deter and prec_temp_deter > 0.15 and len(comb_temp[p]) <= len(best_ancre_deter)  :\n",
    "                    meilleur_prec_deter = prec_temp_deter\n",
    "                    best_ancre = comb_temp[p]\n",
    "                    \n",
    "                elif prec_temp_deter > meilleur_prec_deter : \n",
    "                         meilleur_prec_deter = prec_temp_deter\n",
    "                         best_ancre_deter = comb_temp[p]\n",
    "                \n",
    "                if prec_temp_bert == meilleur_prec_bert and prec_temp_bert > 0.15 and len(comb_temp[p]) <= len(best_ancre_bert)  :\n",
    "                    meilleur_prec_bert = prec_temp_bert\n",
    "                    best_ancre_bert = comb_temp[p]\n",
    "                    \n",
    "                elif prec_temp_bert > meilleur_prec_bert : \n",
    "                         meilleur_prec_bert = prec_temp_bert\n",
    "                         best_ancre_bert = comb_temp[p]\n",
    "                        \n",
    "                    \n",
    "                 \n",
    "print('Anchor:', best_ancre , 'Precision:', meilleur_prec )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "explainer = anchor_text.AnchorText(nlp, ['negative', 'positive'], use_unk_distribution=True) #UNK\n",
    "explainer2 = anchor_text.AnchorText(nlp, ['negative', 'positive'], use_unk_distribution=False ) #BERT\n",
    "np.random.seed(1)\n",
    "text = \"This is good computer\"\n",
    "pred = explainer.class_names[predict_lr([text])[0]]\n",
    "\n",
    "exp_UNK = explainer.explain_instance(text, predict_lr, threshold=0.95, verbose=False)\n",
    "exp_BERT = explainer2.explain_instance(text, predict_lr, threshold=0.95, verbose=False)\n",
    "\n",
    "prec_package_UNK = exp_UNK.precision()\n",
    "ancre_package_UNK = exp_UNK.names()\n",
    "index_ancre_UNK = candidat_tous.index(ancre_package_UNK )\n",
    "\n",
    "list_package_UNK = [0]* len(candidat_tous)\n",
    "list_package_UNK[index_ancre_UNK] = prec_package_UNK\n",
    "\n",
    "\n",
    "prec_package_BERT = exp_BERT.precision() #0.9803921568627451 (aléatoire - on obtient des fois 1.0)\n",
    "ancre_package_BERT = exp_BERT.names()\n",
    "index_ancre_BERT = candidat_tous.index(ancre_package_BERT)\n",
    "\n",
    "list_package_BERT = [0]* len(candidat_tous)\n",
    "list_package_BERT[index_ancre_BERT] = prec_package_BERT\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cov_nor = []\n",
    "\n",
    "for i in vrai_cov : \n",
    "    cov_nor.append(i/100)\n",
    "\n",
    "largeur_barre = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(len(candidat_tous))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_aph = list(map(chr, range(97, 123))) \n",
    "\n",
    "list_aff = precision_tous_bert\n",
    "list_aff2 = precision_tous_deter\n",
    "x_moi_BERT = np.arange(len(candidat_tous))\n",
    "x_pack_BERT = [i - largeur_barre for i in x_moi_BERT]\n",
    "x_moi_UNK = [i + largeur_barre for i in x_moi_BERT]\n",
    "x_pack_UNK = [i + 2*largeur_barre for i in x_moi_BERT]\n",
    "\n",
    "x_cov = [i + 3*largeur_barre for i in x_moi_BERT] # Position des barres de la cat 2\n",
    "\n",
    "\n",
    "plt.bar(x_pack_UNK, height=list_package_UNK,color=\"red\",width = largeur_barre)\n",
    "plt.bar(x_pack_BERT, height=list_package_BERT,color=\"red\",width = largeur_barre)\n",
    "plt.bar(x_moi_BERT, height=list_aff,color=\"green\",width = largeur_barre)\n",
    "plt.bar(x_moi_UNK, height=list_aff2,color=\"orange\",width = largeur_barre)\n",
    "plt.bar(x_cov, height=cov_nor,color=\"pink\",width = largeur_barre)\n",
    "plt.xticks(x_moi_BERT,list_aph[0:len(candidat_tous)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En rouge - Précision obtenue avec le package pour l'ancre $\\texttt{good}; Le résultat est aléatoire - On obtient une précision entre [0.97,1.0] avec une méthode BERT et toujours 1.0 avec une méthode déterministe. Avec notre implémentation pour une méthode générative (BERT), on obtient plus souvent une précision de 0.98, nous sommes limiter par la complexité algorithme de la perturbation par BERT, nous ne pouvons pas générer beaucoup de perturbation. Il est donc plus difficile de trouver une ancre. Avec la perturbation UNK , on trouve une précision de 1.0 presque surement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "\n",
    "model = Pipeline(\n",
    "    [\n",
    "        (\"vectorizer\",  vectorizer),\n",
    "        (\"transformer\", TfidfTransformer()),\n",
    "        (\"classifier\", c),\n",
    "    ]\n",
    ")\n",
    "\n",
    "coefs = model.named_steps[\"classifier\"].coef_.flatten()\n",
    "feature_names = model.named_steps[\"vectorizer\"].get_feature_names()\n",
    "zipped = zip(feature_names, coefs)\n",
    "df = pd.DataFrame(zipped, columns=[\"feature\", \"value\"])\n",
    "# Sort the features by the absolute value of their coefficient\n",
    "df[\"abs_value\"] = df[\"value\"].apply(lambda x: abs(x))\n",
    "df[\"colors\"] = df[\"value\"].apply(lambda x: \"green\" if x > 0 else \"red\")\n",
    "df = df.sort_values(\"abs_value\", ascending=False)\n",
    "\n",
    "coefs = model.named_steps[\"classifier\"].coef_.flatten()\n",
    "feature_names = model.named_steps[\"vectorizer\"].get_feature_names()\n",
    "zipped = zip(feature_names, coefs)\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 7))\n",
    "sns.barplot(x=\"feature\",\n",
    "            y=\"value\",\n",
    "            data=df.head(20),\n",
    "           palette=df.head(20)[\"colors\"])\n",
    "\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, fontsize=20)\n",
    "ax.set_title(\"Les 20 mots les plus influents \", fontsize=25)\n",
    "ax.set_ylabel(\"Coefficient\", fontsize=22)\n",
    "ax.set_xlabel(\"Mot\", fontsize=22)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "les_phrase = [\"But I thought his acting was skilled.\",\"  All of the main players are mesmerising.\",\" The Jamaican mojitos are delicious.\",\"  Great food and service, huge portions and they give a military discount.\",\"  I like this restaurant ; Will be back again !.\",\"  Penne back vodka excellent !\",\"  I LOVED their mussels cooked\",\"  My 8/10 score is mostly for the plot.\",\"  Everything was fresh and delicious !\",\"  My first visit to Hiro was a delight !\",\" definitely will come back here again..\",\"  2 times - Very Bad Customer Service !\",\"  They have horrible attitudes\",\"  It was not good.','  This place is way too overpriced for mediocre food.\",\"  Won’t ever go here again.\",\"  Dont waste your money...\",\" Buyer–Be Very Careful ! ! ! ! !.\",\" Really horrible, cold meal and rude waiter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(les_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meilleur_ancre_general import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "explainer = anchor_text.AnchorText(nlp, ['negative', 'positive'], use_unk_distribution=True)\n",
    "\n",
    "for i in les_phrase : \n",
    "    #print(i)\n",
    "    label = predict_lr([i])[0]\n",
    "   \n",
    "    meilleur_ancre_bis_new(df,i,100,\"UNK\",label,0.15,vectorizer,c )\n",
    "    exp3 = explainer.explain_instance(i, predict_lr, threshold=0.95)\n",
    "    print('Anchor_p: %s' % (' AND '.join(exp3.names())),'Precision_p: %.2f' % exp3.precision())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
